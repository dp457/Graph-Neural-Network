{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbo4nT6tbM7TPHNm9DUoYv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dp457/Graph-Neural-Network/blob/main/Creating_the_Message_Passing_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The convolution operator expressed as neighbourhood aggregation or message passing scheme. With $\\mathbf{x}^{(k-1)}_i \\in \\mathbb{R}^F$ denoting the node features of node $i$ in layer $\\left (k-1 \\right )$ and $\\mathbf{e}_{j,i} \\in \\mathbb{R}^D$ denote the optional edge features from node $j$  to node $i$, hence the message passing GNN can be described as,\n",
        "\n",
        "$\\mathbf{x}_i^{(k)}\n",
        "= \\gamma^{(k)} \\left(\n",
        "    \\mathbf{x}_i^{(k-1)},\n",
        "    \\bigoplus_{j \\in \\mathcal{N}(i)}\n",
        "        \\phi^{(k)} \\left(\n",
        "            \\mathbf{x}_i^{(k-1)},\n",
        "            \\mathbf{x}_j^{(k-1)},\n",
        "            \\mathbf{e}_{j,i}\n",
        "        \\right)\n",
        "\\right),$\n",
        "\n",
        "Here $\\bigoplus$ represents differentiable, permutation invariant functions e.g. sum, mean or max and $\\gamma$ and $\\phi$ denote the differentiable functions such as MLPs.\n",
        ""
      ],
      "metadata": {
        "id": "fsul7WSXEoW_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Message Passing Base Class\n",
        "\n",
        "*   Define the aggregation scheme to use (\"add\", \"mean\" or \"max\") and flow direction of message passing. (\"source_to_target\" and \"target_to_source\"). Node dimensions help in obtaining which dimensions to propoagate\n",
        "*   **.propagate()** - Initial call to start propagating the messages.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZIRE0SvzJ_HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h-bSZN-NrxW",
        "outputId": "522a66fe-ca29-4816-aa1c-690b13b63bbc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing the GCN layer\n",
        "\n",
        "The layer is mathematically defined as:\n",
        "$\\mathbf{x}_i^{(k)} = \\sum_{j \\in \\mathcal{N}(i) \\cup \\{i\\}} \\frac{1}{\\sqrt{\\deg(i)} \\cdot \\sqrt{\\deg(j)}}  \\cdot \\left( \\mathbf{W}^\\top \\cdot \\mathbf{x}_j^{(k-1)} \\right)  + \\mathbf{b}  $\n",
        "\n",
        "The formula is divided into following steps\n",
        "*   Add self loops to the adjacency matrix.\n",
        "*   Linearly transform the node feature matrix.\n",
        "*   Compute the normalization coefficients.\n",
        "*   Normalize the node feaures $\\phi$.\n",
        "*   Sum up neighbouring node features.\n",
        "*   Apply the final bias vector.\n",
        "\n",
        "Steps 1-3 typically computed before message passing take place. Steps 4-5 can be implemented using **MessagePassing** base class. The implementation is given as follows:"
      ],
      "metadata": {
        "id": "uZPaMtgLOja7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Linear, Parameter\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "\n",
        "class GCNConv(MessagePassing):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__(aggr='add')\n",
        "    self.lin = Linear(in_channels, out_channels, bias=False)\n",
        "    self.bias = Parameter(torch.empty(out_channels))\n",
        "\n",
        "    self.reset_parameters()\n",
        "\n",
        "  def reset_parameters(self):\n",
        "    self.lin.reset_parameters()\n",
        "    self.bias.data.zero_()\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x has shape [N, in_channels]\n",
        "    # edge_index has shape [2,E].\n",
        "\n",
        "    # Step 1. Add self-loops to the adjacency matrix\n",
        "    edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
        "\n",
        "    # Step 2. Linearly transform the feature matrix\n",
        "    x = self.lin(x)\n",
        "\n",
        "    # Step 3. Compute normalization\n",
        "    row, col = edge_index\n",
        "    deg = degree(col, x.size(0), dtype=x.dtype)\n",
        "    deg_inv_sqrt = deg.pow(-0.5)\n",
        "    deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
        "    norm = deg_inv_sqrt[row]*deg_inv_sqrt[col]\n",
        "\n",
        "    # Step 4-5 : Start propagating the messages\n",
        "    out = self.propagate(edge_index, x=x, norm=norm) # internally calls message(), aggregate() and update()\n",
        "\n",
        "    # Step 6: Apply a final bias vector\n",
        "    out = out + self.bias\n",
        "\n",
        "    return out\n",
        "\n",
        "  def message(self, x_j, norm):\n",
        "    # x_j has shape [E, out_channels]\n",
        "\n",
        "    #Step 4: Normalize the node features\n",
        "    return norm.view(-1,1)*x_j\n"
      ],
      "metadata": {
        "id": "9sQbH3nuSUbY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.transforms import NormalizeFeatures"
      ],
      "metadata": {
        "id": "0YzSa8UNu0Ct"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GCN Model\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "giMybsQpu-oe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilities\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def set_seed(seed: int = 0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "20efP5iZvNej"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(logits, y, mask):\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    correct = int((preds[mask] == y[mask]).sum())\n",
        "    total = int(mask.sum())\n",
        "    return correct / max(total, 1)"
      ],
      "metadata": {
        "id": "sUUXLABDvW0N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Training / Evaluation\n",
        "# ----------------------------\n",
        "def train(model, data, optimizer, weight_decay=5e-4):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask])\n",
        "    # L2 on all parameters as in Kipf and Welling\n",
        "    l2 = sum((p**2).sum() for p in model.parameters())\n",
        "    loss = loss + weight_decay * l2\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.item())\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    logits = model(data.x, data.edge_index)\n",
        "    loss_val = F.cross_entropy(logits[data.val_mask], data.y[data.val_mask]).item()\n",
        "    loss_test = F.cross_entropy(logits[data.test_mask], data.y[data.test_mask]).item()\n",
        "    acc_train = accuracy(logits, data.y, data.train_mask)\n",
        "    acc_val = accuracy(logits, data.y, data.val_mask)\n",
        "    acc_test = accuracy(logits, data.y, data.test_mask)\n",
        "    return {\n",
        "        \"val_loss\": loss_val,\n",
        "        \"test_loss\": loss_test,\n",
        "        \"train_acc\": acc_train,\n",
        "        \"val_acc\": acc_val,\n",
        "        \"test_acc\": acc_test,\n",
        "    }"
      ],
      "metadata": {
        "id": "RHktJys3vYm0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from torch.optim import Adam\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"GCN with custom GCNConv on Planetoid datasets\")\n",
        "    parser.add_argument(\"--dataset\", type=str, default=\"Cora\", choices=[\"Cora\", \"CiteSeer\", \"PubMed\"])\n",
        "    parser.add_argument(\"--root\", type=str, default=\"./data\")\n",
        "    parser.add_argument(\"--hidden\", type=int, default=64)\n",
        "    parser.add_argument(\"--dropout\", type=float, default=0.5)\n",
        "    parser.add_argument(\"--epochs\", type=int, default=400)\n",
        "    parser.add_argument(\"--lr\", type=float, default=0.01)\n",
        "    parser.add_argument(\"--weight_decay\", type=float, default=5e-4)\n",
        "    parser.add_argument(\"--seed\", type=int, default=0)\n",
        "    parser.add_argument(\"--patience\", type=int, default=100, help=\"Early stopping patience on val loss\")\n",
        "    args, _ = parser.parse_known_args()\n",
        "\n",
        "    set_seed(args.seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    dataset = Planetoid(root=args.root, name=args.dataset, transform=NormalizeFeatures())\n",
        "    data = dataset[0].to(device)\n",
        "\n",
        "    model = GCN(dataset.num_features, args.hidden, dataset.num_classes, dropout=args.dropout).to(device)\n",
        "    optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=0.0)  # manual L2 already added\n",
        "\n",
        "    best_val = float(\"inf\")\n",
        "    best_state = None\n",
        "    patience = args.patience\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        loss = train(model, data, optimizer, weight_decay=args.weight_decay)\n",
        "        metrics = evaluate(model, data)\n",
        "\n",
        "        improved = metrics[\"val_loss\"] < best_val - 1e-6\n",
        "        if improved:\n",
        "            best_val = metrics[\"val_loss\"]\n",
        "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epoch % 10 == 0 or epoch == 1:\n",
        "            print(f\"Epoch {epoch:03d} | \"\n",
        "                  f\"train_acc={metrics['train_acc']:.4f} \"\n",
        "                  f\"val_acc={metrics['val_acc']:.4f} \"\n",
        "                  f\"test_acc={metrics['test_acc']:.4f} \"\n",
        "                  f\"val_loss={metrics['val_loss']:.4f}\")\n",
        "\n",
        "        if patience and epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch}. Best val_loss={best_val:.4f}\")\n",
        "            break\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    final = evaluate(model, data)\n",
        "    print(\"Final metrics:\",\n",
        "          {k: round(v, 4) for k, v in final.items()})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn8-N2RIvgUW",
        "outputId": "f6469312-d943-4215-8442-a2ba922bf22f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | train_acc=0.2071 val_acc=0.1440 test_acc=0.1600 val_loss=1.9414\n",
            "Epoch 010 | train_acc=0.7786 val_acc=0.5680 test_acc=0.5820 val_loss=1.8956\n",
            "Epoch 020 | train_acc=0.8714 val_acc=0.6960 test_acc=0.7170 val_loss=1.7849\n",
            "Epoch 030 | train_acc=0.9357 val_acc=0.7480 test_acc=0.7860 val_loss=1.6156\n",
            "Epoch 040 | train_acc=0.9500 val_acc=0.7820 test_acc=0.8140 val_loss=1.4052\n",
            "Epoch 050 | train_acc=0.9643 val_acc=0.7900 test_acc=0.8160 val_loss=1.2276\n",
            "Epoch 060 | train_acc=0.9643 val_acc=0.7960 test_acc=0.8160 val_loss=1.0943\n",
            "Epoch 070 | train_acc=0.9786 val_acc=0.7940 test_acc=0.8150 val_loss=1.0185\n",
            "Epoch 080 | train_acc=0.9786 val_acc=0.7960 test_acc=0.8100 val_loss=0.9682\n",
            "Epoch 090 | train_acc=0.9857 val_acc=0.7900 test_acc=0.8150 val_loss=0.9354\n",
            "Epoch 100 | train_acc=0.9857 val_acc=0.7940 test_acc=0.8100 val_loss=0.9077\n",
            "Epoch 110 | train_acc=0.9857 val_acc=0.7860 test_acc=0.8100 val_loss=0.8857\n",
            "Epoch 120 | train_acc=0.9857 val_acc=0.7880 test_acc=0.8000 val_loss=0.8767\n",
            "Epoch 130 | train_acc=0.9857 val_acc=0.7900 test_acc=0.8050 val_loss=0.8617\n",
            "Epoch 140 | train_acc=0.9857 val_acc=0.7840 test_acc=0.8070 val_loss=0.8462\n",
            "Epoch 150 | train_acc=0.9857 val_acc=0.7800 test_acc=0.8120 val_loss=0.8380\n",
            "Epoch 160 | train_acc=0.9929 val_acc=0.7900 test_acc=0.8110 val_loss=0.8373\n",
            "Epoch 170 | train_acc=1.0000 val_acc=0.7920 test_acc=0.8130 val_loss=0.8264\n",
            "Epoch 180 | train_acc=1.0000 val_acc=0.7920 test_acc=0.8070 val_loss=0.8315\n",
            "Epoch 190 | train_acc=1.0000 val_acc=0.7940 test_acc=0.8080 val_loss=0.8199\n",
            "Epoch 200 | train_acc=1.0000 val_acc=0.7900 test_acc=0.8050 val_loss=0.8226\n",
            "Epoch 210 | train_acc=0.9929 val_acc=0.7860 test_acc=0.8150 val_loss=0.8093\n",
            "Epoch 220 | train_acc=0.9929 val_acc=0.7900 test_acc=0.8130 val_loss=0.8045\n",
            "Epoch 230 | train_acc=0.9929 val_acc=0.7900 test_acc=0.8100 val_loss=0.8068\n",
            "Epoch 240 | train_acc=1.0000 val_acc=0.7900 test_acc=0.8120 val_loss=0.8053\n",
            "Epoch 250 | train_acc=1.0000 val_acc=0.7980 test_acc=0.8170 val_loss=0.7972\n",
            "Epoch 260 | train_acc=1.0000 val_acc=0.7880 test_acc=0.8070 val_loss=0.8154\n",
            "Epoch 270 | train_acc=1.0000 val_acc=0.7980 test_acc=0.8040 val_loss=0.8159\n",
            "Epoch 280 | train_acc=1.0000 val_acc=0.7980 test_acc=0.8140 val_loss=0.8050\n",
            "Epoch 290 | train_acc=1.0000 val_acc=0.7900 test_acc=0.8090 val_loss=0.8013\n",
            "Epoch 300 | train_acc=1.0000 val_acc=0.7920 test_acc=0.8060 val_loss=0.8196\n",
            "Epoch 310 | train_acc=1.0000 val_acc=0.7880 test_acc=0.8050 val_loss=0.8151\n",
            "Epoch 320 | train_acc=1.0000 val_acc=0.7940 test_acc=0.8120 val_loss=0.8039\n",
            "Epoch 330 | train_acc=1.0000 val_acc=0.8000 test_acc=0.8100 val_loss=0.8036\n",
            "Epoch 340 | train_acc=1.0000 val_acc=0.7900 test_acc=0.8070 val_loss=0.8052\n",
            "Epoch 350 | train_acc=1.0000 val_acc=0.7980 test_acc=0.8110 val_loss=0.7961\n",
            "Epoch 360 | train_acc=1.0000 val_acc=0.7960 test_acc=0.8210 val_loss=0.7939\n",
            "Epoch 370 | train_acc=1.0000 val_acc=0.7920 test_acc=0.8160 val_loss=0.7969\n",
            "Epoch 380 | train_acc=1.0000 val_acc=0.7900 test_acc=0.8100 val_loss=0.8100\n",
            "Epoch 390 | train_acc=1.0000 val_acc=0.7920 test_acc=0.8040 val_loss=0.8115\n",
            "Epoch 400 | train_acc=1.0000 val_acc=0.7880 test_acc=0.8120 val_loss=0.8023\n",
            "Final metrics: {'val_loss': 0.7892, 'test_loss': 0.7618, 'train_acc': 0.9929, 'val_acc': 0.792, 'test_acc': 0.813}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementating the Edge Convolution\n",
        "\n",
        "It processes graphs and point cloud data and mathematically defined as,\n",
        "\n",
        "$\\mathbf{x}_i^{(k)} = \\max_{j \\in \\mathcal{N}(i)} h_{\\Theta} \\left ( \\mathbf{x}_i^{(k-1)}, \\mathbf{x}_j^{(k-1)} - \\mathbf{x}_i^{(k-1)} \\right ) $\n",
        "\n",
        "Here $h_{\\Theta}$ represents MLP. In analogy to the GCN we use this class to implement this class."
      ],
      "metadata": {
        "id": "rgFYWQ1VW3dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import Sequential as Seq, Linear, ReLU\n",
        "from torch_geometric.nn import MessagePassing\n",
        "\n",
        "class EdgeConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__(aggr='max') #  \"Max\" aggregation.\n",
        "        self.mlp = Seq(Linear(2 * in_channels, out_channels),\n",
        "                       ReLU(),\n",
        "                       Linear(out_channels, out_channels))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # x has shape [N, in_channels]\n",
        "        # edge_index has shape [2, E]\n",
        "\n",
        "        return self.propagate(edge_index, x=x)\n",
        "\n",
        "    def message(self, x_i, x_j):\n",
        "        # x_i has shape [E, in_channels]\n",
        "        # x_j has shape [E, in_channels]\n",
        "\n",
        "        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
        "        return self.mlp(tmp)"
      ],
      "metadata": {
        "id": "jsbC0tzRO99D"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Edge convolution is a dynamic convolution that computes graph for each layer using nearest neighbours in the feature space. The way to implement this is given as follows"
      ],
      "metadata": {
        "id": "9ppsyVnhtrT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import knn_graph\n",
        "\n",
        "class DynamicEdgeConv(EdgeConv):\n",
        "    def __init__(self, in_channels, out_channels, k=6):\n",
        "        super().__init__(in_channels, out_channels)\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, x, batch=None):\n",
        "        edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)\n",
        "        return super().forward(x, edge_index)"
      ],
      "metadata": {
        "id": "2AhNt_WYt4F6"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}