{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOshdXv8XS09As1D+835qn7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dp457/Graph-Neural-Network/blob/main/Temporal_Graph_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temporal Graph Network (TGN) link-prediction example on JODIE–Wikipedia dataset. It implements,\n",
        "1. Learned node memory\n",
        "2. Message/aggregation pipeline.\n",
        "3. Temporal graph attention style embedding\n",
        "4. MLP decoder for link probability.\n",
        "\n",
        "1. **High level** --> model keeps a per-node memory $s_{i} (t)$ that gets updated only when node $i$ participates in an event.\n",
        "2. **Temporal GNN embedding module**, aggregates the most-recent neighbors, using attention with **time-encodings** and **edge-messages**.\n",
        "3. **Decoder** predicts when a source-destination interaction occurs.\n",
        "\n",
        "Encoder–decoder view of dynamic graphs described by TGN, with specific choices -> identity message function, last message aggregation and GRU-style memory and **one-layer temporal attention embedding**.\n",
        "\n"
      ],
      "metadata": {
        "id": "OkG9UgnPX7m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdOYj2gUcLPx",
        "outputId": "0c86e478-d65e-48c7-d91b-c84aef073244"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data and Task\n",
        "\n",
        "1. **Temporal events:** Chronologically ordered list of interactions $e_{ij} (t)$ (user $i$ edits page $j$ at time $t$) possibly with edge features/messages $x_{ij} (t)$. Dynamic graphs are formalized as a sequence of stamped events $G = \\{ x(t_1), x(t_2), \\cdots \\}.$\n",
        "\n",
        "2. **Tasks:** Given past events up to some time, predict whether the next batch’s edges occur. TGN uses this task as the canonical self-supervised training objective.\n",
        "\n",
        "The loaders *TemporalDataLoader* and *LastNeighborLoader* maintain temporal order and sample the most recent-neighbors (size 10) and create negatives at 1:1 ratio. Most-recent sampling is a recommended TGN choice: it outperforms uniform neighbor sampling on dynamic data."
      ],
      "metadata": {
        "id": "KeN7T1UvcsJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "from torch.nn import Linear\n",
        "\n",
        "from torch_geometric.datasets import JODIEDataset\n",
        "from torch_geometric.loader import TemporalDataLoader\n",
        "from torch_geometric.nn import TGNMemory, TransformerConv\n",
        "from torch_geometric.nn.models.tgn import (\n",
        "    IdentityMessage,\n",
        "    LastAggregator,\n",
        "    LastNeighborLoader,\n",
        ")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "path = osp.join('data', 'JODIE')\n",
        "dataset = JODIEDataset(path, name='wikipedia')\n",
        "data = dataset[0]\n",
        "\n",
        "# For small datasets, we can put the whole dataset on GPU and thus avoid\n",
        "# expensive memory transfer costs for mini-batches:\n",
        "data = data.to(device)\n",
        "\n",
        "train_data, val_data, test_data = data.train_val_test_split(\n",
        "    val_ratio=0.15, test_ratio=0.15)\n",
        "\n",
        "train_loader = TemporalDataLoader(\n",
        "    train_data,\n",
        "    batch_size=200,\n",
        "    neg_sampling_ratio=1.0,\n",
        ")\n",
        "val_loader = TemporalDataLoader(\n",
        "    val_data,\n",
        "    batch_size=200,\n",
        "    neg_sampling_ratio=1.0,\n",
        ")\n",
        "test_loader = TemporalDataLoader(\n",
        "    test_data,\n",
        "    batch_size=200,\n",
        "    neg_sampling_ratio=1.0,\n",
        ")\n",
        "neighbor_loader = LastNeighborLoader(data.num_nodes, size=10, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vUX7dB_cY41",
        "outputId": "f2471bc4-1803-40d5-9383-ca175050f349"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading http://snap.stanford.edu/jodie/wikipedia.csv\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. TGN Core Modules\n",
        "\n",
        "## 2.1 Per-node memory $s_i (t)$\n",
        "\n",
        "TGN maintains a vector state $s_i (t)$ for each node $i$, updated after processing an event,\n",
        "\n",
        "\\begin{equation}\n",
        " s_{i} (t) = \\text{mem} (\\tilde{m}_i (t), s_i (t^-))\n",
        " \\end{equation}\n",
        "\n",
        "Here $t^-$ s the previous time $i$ was involved in an event, and $\\tilde{m}_i (t)$ is the aggregate of batch's messages for $i$.\n",
        "\n",
        "\n",
        "**Message functions** - For an interaction $e_{ij} (t)$ TGN forms two messages,\n",
        "$m_{i} (t) = \\text{msg}_s (s_i (t^-), s_j (t^-), \\Delta t, e_{ij}(t))$,\n",
        "$m_{j} (t) = \\text{msg}_d (s_j (t^-), s_i (t^-), \\Delta t, e_{ij}(t))$\n",
        "\n",
        "Here, the $\\text{msg}$ is the identity.\n",
        "\n",
        "## 2.2 Embedding module: temporal attention with time encoding,\n",
        "\n",
        "TGN computes a temporal embedding $z_i (t)$ by aggregating the temporal $k-$hop neighborhood using a graph attention layer with time encoder $\\phi(\\cdot)$:\n",
        "\n",
        "\\begin{align}\n",
        "h_i^{(\\ell)}(t) &= \\text{MLP}^{(\\ell)}\\!\\left(h_i^{(\\ell-1)}(t) \\; \\| \\; \\tilde{h}_i^{(\\ell)}(t)\\right), \\\\\n",
        "\\tilde{h}_i^{(\\ell)} &= \\text{MultiHeadAttn}^{(\\ell)} \\!\\left(q^{(\\ell)}(t), K^{(\\ell)}(t), V^{(\\ell)}(t)\\right), \\\\\n",
        "q^{(\\ell)}(t) &= h_i^{(\\ell-1)}(t) \\; \\| \\; \\phi(0), \\\\\n",
        "K^{(\\ell)}(t) = V^{(\\ell)}(t) &= \\left[h_j^{(\\ell-1)}(t) \\; \\| \\; e_{ij} \\; \\| \\; \\phi(t - t_j)\\right]_{j \\in \\mathcal{N}_i(\\{0,t\\})}, \\\\\n",
        "z_i(t) &= h_i^{(L)}(t)\n",
        "\\end{align}\n",
        "\n",
        "This is the TGN-attention embedding, (a TGAT-style temporal graph attention driven by node memories and time encodings).\n",
        "\n",
        "Embedding via temporal attention\n",
        "\n",
        "*TransformerConv:* Multi-head graph attention operator\n",
        "*   For each node $i$, it attends over neighbours $j$ with queries from $s_i (t)$ keys and values from $[s_j (t) || e_{ij} (t) ]$\n",
        "*   The attention weight is computed as,\n",
        "\\begin{equation}\n",
        "\\alpha_{ij} = \\frac{\\exp\\left( \\langle Q_i, K_{ij} \\rangle \\right)}{\\sum_{k \\in \\mathcal{N}(i)} \\exp\\left( \\langle Q_i, K_{ik} \\rangle \\right)},\n",
        "\\end{equation}\n",
        "where, $Q_i = W_q s_i (t)$, $K_{ij} = W_k [s_j (t) || e_{ij} (t)]$\n",
        "*  Then time-aware temporal embeddings $z_{i} (t)$ is given as,\n",
        "\\begin{equation}\n",
        "z_i(t) = \\sum_{j \\in \\mathcal{N}(i)} \\alpha_{ij} W_v \\big[ s_j(t) \\,\\|\\, e_{ij}(t) \\big].\n",
        "\\end{equation}\n",
        "\n",
        "gnn object transforms node memories into temporal embeddings that capture:\n",
        "*   memory of past interactions\n",
        "*   recent-neighbour influence via attention\n",
        "*   edge-level context (message + time difference)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NJYFm2QOdwld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphAttentionEmbedding(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, msg_dim, time_enc):\n",
        "        super().__init__()\n",
        "        self.time_enc = time_enc\n",
        "        edge_dim = msg_dim + time_enc.out_channels\n",
        "        self.conv = TransformerConv(in_channels, out_channels // 2, heads=2,\n",
        "                                    dropout=0.1, edge_dim=edge_dim) # Realizes multi-head attention over sampled neighbourhood\n",
        "\n",
        "    def forward(self, x, last_update, edge_index, t, msg):\n",
        "        rel_t = last_update[edge_index[0]] - t   # relative time\n",
        "        rel_t_enc = self.time_enc(rel_t.to(x.dtype)) # relative time encoding\n",
        "        edge_attr = torch.cat([rel_t_enc, msg], dim=-1)\n",
        "        return self.conv(x, edge_index, edge_attr) #temporal emeddings\n",
        "\n",
        "\n",
        "class LinkPredictor(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.lin_src = Linear(in_channels, in_channels)\n",
        "        self.lin_dst = Linear(in_channels, in_channels)\n",
        "        self.lin_final = Linear(in_channels, 1)\n",
        "\n",
        "    def forward(self, z_src, z_dst):\n",
        "        h = self.lin_src(z_src) + self.lin_dst(z_dst)\n",
        "        h = h.relu()\n",
        "        return self.lin_final(h)\n",
        "\n",
        "\n",
        "memory_dim = time_dim = embedding_dim = 100\n",
        "\n",
        "\n",
        "# For each node i, TGN keeps a memory vector, Memory updated by aggregating the most\n",
        "# message m_i (t) (via  GRU like update)\n",
        "# s_i, s_j , time encoding of delay since last update, x_ij (t)\n",
        "\n",
        "memory = TGNMemory(\n",
        "    data.num_nodes,\n",
        "    data.msg.size(-1),\n",
        "    memory_dim,\n",
        "    time_dim,\n",
        "    message_module=IdentityMessage(data.msg.size(-1), memory_dim, time_dim),\n",
        "    aggregator_module=LastAggregator(),\n",
        ").to(device)\n",
        "\n",
        "\n",
        "\n",
        "gnn = GraphAttentionEmbedding(\n",
        "    in_channels=memory_dim,  # input - memory vector size\n",
        "    out_channels=embedding_dim, # output embedding dimension\n",
        "    msg_dim=data.msg.size(-1), # dimension of edge message\n",
        "    time_enc=memory.time_enc, # same Time2Vec module used by memory\n",
        ").to(device)\n"
      ],
      "metadata": {
        "id": "Fal_MG9eijNI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Linkpredictor computes the score\n",
        "\\begin{equation}\n",
        "\\text{score} (i,j) = w^T \\sigma (W_s z_i (t) + W_d z_j (t))\n",
        "\\end{equation}\n",
        "\n",
        "The training done with balanced BCE on positives/negatives i.e\n",
        "\n",
        "$\\mathcal{L} = \\text{BCE} ( \\text{score(i,j)}, 1) + \\text{BCE} (\\text{score} (i, \\tilde{j}),0)$\n",
        "\n",
        "This is exactly the TGN link-prediction objective (compute embeddings, decode edge probability, BCE).\n",
        "\n",
        "The key subtelty in TGN -> when the interaction update the memory. If the memory is updated with current batch's interaction before predicting the same interaction , the model would peek into the future.\n",
        "\n",
        "**Problem: Temporal Leakage**\n",
        "Imagine predicting whether the edge $(i,j,t)$ exists at time $t$. Each node has the memory vector $s_i (t)$.\n",
        "\n",
        "*   If $s_i (t)$ is updated with information of $(i,j,t)$ before trying to predict the edge, the model has \"peeked\" the answer which is known as **data leakage**.\n",
        "*   The prediction would be unrealistic, because in a real-world setting you only have access to past events, not the current one you are trying to predict.\n",
        "\n",
        "**Solution: Raw Message Store**\n",
        "\n",
        "1. Store Messages but do not update immediately.\n",
        "\n",
        "When a new interaction $(i,j,t)$ arrives, create a raw message for node $i$ and $j$ (containing memories, edge features, and time differences). But do not update their memories, just keep it aside.\n",
        "\n",
        "2. Predict using the old memory.\n",
        "3. After prediction update the memory.\n",
        "\n"
      ],
      "metadata": {
        "id": "UkmaZDvuWBzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link_pred = LinkPredictor(in_channels=embedding_dim).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    set(memory.parameters()) | set(gnn.parameters())\n",
        "    | set(link_pred.parameters()), lr=0.0001)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Helper vector to map global node indices to local ones.\n",
        "assoc = torch.empty(data.num_nodes, dtype=torch.long, device=device)\n"
      ],
      "metadata": {
        "id": "GWQzsyteU1Ot"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    memory.train()\n",
        "    gnn.train()\n",
        "    link_pred.train()\n",
        "\n",
        "    memory.reset_state()  # Start with a fresh memory.\n",
        "    neighbor_loader.reset_state()  # Start with an empty graph.\n",
        "\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
        "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
        "\n",
        "        # Get updated memory of all nodes involved in the computation.\n",
        "        z, last_update = memory(n_id)\n",
        "        z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
        "                data.msg[e_id].to(device))\n",
        "        pos_out = link_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
        "        neg_out = link_pred(z[assoc[batch.src]], z[assoc[batch.neg_dst]])\n",
        "\n",
        "        loss = criterion(pos_out, torch.ones_like(pos_out))\n",
        "        loss += criterion(neg_out, torch.zeros_like(neg_out))\n",
        "\n",
        "        # Update memory and neighbor loader with ground-truth state.\n",
        "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
        "        neighbor_loader.insert(batch.src, batch.dst)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        memory.detach()\n",
        "        total_loss += float(loss) * batch.num_events\n",
        "\n",
        "    return total_loss / train_data.num_events\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "    memory.eval()\n",
        "    gnn.eval()\n",
        "    link_pred.eval()\n",
        "\n",
        "    torch.manual_seed(12345)  # Ensure deterministic sampling across epochs.\n",
        "\n",
        "    aps, aucs = [], []\n",
        "    for batch in loader:\n",
        "        batch = batch.to(device)\n",
        "\n",
        "        n_id, edge_index, e_id = neighbor_loader(batch.n_id)\n",
        "        assoc[n_id] = torch.arange(n_id.size(0), device=device)\n",
        "\n",
        "        z, last_update = memory(n_id)\n",
        "        z = gnn(z, last_update, edge_index, data.t[e_id].to(device),\n",
        "                data.msg[e_id].to(device))\n",
        "        pos_out = link_pred(z[assoc[batch.src]], z[assoc[batch.dst]])\n",
        "        neg_out = link_pred(z[assoc[batch.src]], z[assoc[batch.neg_dst]])\n",
        "\n",
        "        y_pred = torch.cat([pos_out, neg_out], dim=0).sigmoid().cpu()\n",
        "        y_true = torch.cat(\n",
        "            [torch.ones(pos_out.size(0)),\n",
        "             torch.zeros(neg_out.size(0))], dim=0)\n",
        "\n",
        "        aps.append(average_precision_score(y_true, y_pred))\n",
        "        aucs.append(roc_auc_score(y_true, y_pred))\n",
        "\n",
        "        memory.update_state(batch.src, batch.dst, batch.t, batch.msg)\n",
        "        neighbor_loader.insert(batch.src, batch.dst)\n",
        "    return float(torch.tensor(aps).mean()), float(torch.tensor(aucs).mean())\n",
        "\n",
        "\n",
        "for epoch in range(1, 51):\n",
        "    loss = train()\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}')\n",
        "    val_ap, val_auc = test(val_loader)\n",
        "    test_ap, test_auc = test(test_loader)\n",
        "    print(f'Val AP: {val_ap:.4f}, Val AUC: {val_auc:.4f}')\n",
        "    print(f'Test AP: {test_ap:.4f}, Test AUC: {test_auc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYJq-SmkU7Xs",
        "outputId": "9c1bd744-72b4-41bd-d64c-96bfd89aad8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-734259517.py:34: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
            "  total_loss += float(loss) * batch.num_events\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01, Loss: 1.1204\n",
            "Val AP: 0.8507, Val AUC: 0.8676\n",
            "Test AP: 0.8165, Test AUC: 0.8394\n",
            "Epoch: 02, Loss: 0.8843\n",
            "Val AP: 0.9203, Val AUC: 0.9193\n",
            "Test AP: 0.9158, Test AUC: 0.9131\n",
            "Epoch: 03, Loss: 0.7189\n",
            "Val AP: 0.9464, Val AUC: 0.9407\n",
            "Test AP: 0.9406, Test AUC: 0.9352\n",
            "Epoch: 04, Loss: 0.6698\n",
            "Val AP: 0.9499, Val AUC: 0.9440\n",
            "Test AP: 0.9443, Test AUC: 0.9384\n",
            "Epoch: 05, Loss: 0.6475\n",
            "Val AP: 0.9531, Val AUC: 0.9483\n",
            "Test AP: 0.9504, Test AUC: 0.9453\n",
            "Epoch: 06, Loss: 0.6359\n",
            "Val AP: 0.9524, Val AUC: 0.9485\n",
            "Test AP: 0.9432, Test AUC: 0.9386\n",
            "Epoch: 07, Loss: 0.6218\n",
            "Val AP: 0.9553, Val AUC: 0.9508\n",
            "Test AP: 0.9480, Test AUC: 0.9428\n",
            "Epoch: 08, Loss: 0.6077\n",
            "Val AP: 0.9590, Val AUC: 0.9547\n",
            "Test AP: 0.9520, Test AUC: 0.9478\n",
            "Epoch: 09, Loss: 0.5997\n",
            "Val AP: 0.9564, Val AUC: 0.9522\n",
            "Test AP: 0.9508, Test AUC: 0.9466\n",
            "Epoch: 10, Loss: 0.5820\n",
            "Val AP: 0.9587, Val AUC: 0.9546\n",
            "Test AP: 0.9516, Test AUC: 0.9472\n",
            "Epoch: 11, Loss: 0.5740\n",
            "Val AP: 0.9602, Val AUC: 0.9564\n",
            "Test AP: 0.9537, Test AUC: 0.9497\n",
            "Epoch: 12, Loss: 0.5611\n",
            "Val AP: 0.9614, Val AUC: 0.9566\n",
            "Test AP: 0.9530, Test AUC: 0.9481\n",
            "Epoch: 13, Loss: 0.5548\n",
            "Val AP: 0.9623, Val AUC: 0.9581\n",
            "Test AP: 0.9572, Test AUC: 0.9524\n",
            "Epoch: 14, Loss: 0.5450\n",
            "Val AP: 0.9631, Val AUC: 0.9586\n",
            "Test AP: 0.9584, Test AUC: 0.9537\n",
            "Epoch: 15, Loss: 0.5366\n",
            "Val AP: 0.9640, Val AUC: 0.9593\n",
            "Test AP: 0.9575, Test AUC: 0.9537\n",
            "Epoch: 16, Loss: 0.5233\n",
            "Val AP: 0.9658, Val AUC: 0.9615\n",
            "Test AP: 0.9602, Test AUC: 0.9560\n",
            "Epoch: 17, Loss: 0.5193\n",
            "Val AP: 0.9648, Val AUC: 0.9598\n",
            "Test AP: 0.9600, Test AUC: 0.9555\n",
            "Epoch: 18, Loss: 0.5058\n",
            "Val AP: 0.9660, Val AUC: 0.9617\n",
            "Test AP: 0.9621, Test AUC: 0.9583\n",
            "Epoch: 19, Loss: 0.5005\n",
            "Val AP: 0.9664, Val AUC: 0.9619\n",
            "Test AP: 0.9623, Test AUC: 0.9579\n",
            "Epoch: 20, Loss: 0.4967\n",
            "Val AP: 0.9667, Val AUC: 0.9629\n",
            "Test AP: 0.9610, Test AUC: 0.9571\n",
            "Epoch: 21, Loss: 0.4944\n",
            "Val AP: 0.9661, Val AUC: 0.9621\n",
            "Test AP: 0.9620, Test AUC: 0.9579\n",
            "Epoch: 22, Loss: 0.4952\n",
            "Val AP: 0.9673, Val AUC: 0.9633\n",
            "Test AP: 0.9604, Test AUC: 0.9576\n",
            "Epoch: 23, Loss: 0.4895\n",
            "Val AP: 0.9672, Val AUC: 0.9636\n",
            "Test AP: 0.9624, Test AUC: 0.9585\n",
            "Epoch: 24, Loss: 0.4809\n",
            "Val AP: 0.9669, Val AUC: 0.9629\n",
            "Test AP: 0.9616, Test AUC: 0.9573\n",
            "Epoch: 25, Loss: 0.4793\n",
            "Val AP: 0.9674, Val AUC: 0.9634\n",
            "Test AP: 0.9630, Test AUC: 0.9580\n",
            "Epoch: 26, Loss: 0.4742\n",
            "Val AP: 0.9682, Val AUC: 0.9637\n",
            "Test AP: 0.9630, Test AUC: 0.9596\n",
            "Epoch: 27, Loss: 0.4716\n",
            "Val AP: 0.9692, Val AUC: 0.9655\n",
            "Test AP: 0.9630, Test AUC: 0.9593\n",
            "Epoch: 28, Loss: 0.4649\n",
            "Val AP: 0.9685, Val AUC: 0.9646\n",
            "Test AP: 0.9622, Test AUC: 0.9592\n",
            "Epoch: 29, Loss: 0.4608\n",
            "Val AP: 0.9688, Val AUC: 0.9654\n",
            "Test AP: 0.9629, Test AUC: 0.9596\n",
            "Epoch: 30, Loss: 0.4643\n",
            "Val AP: 0.9690, Val AUC: 0.9655\n",
            "Test AP: 0.9643, Test AUC: 0.9609\n",
            "Epoch: 31, Loss: 0.4610\n",
            "Val AP: 0.9684, Val AUC: 0.9645\n",
            "Test AP: 0.9643, Test AUC: 0.9600\n",
            "Epoch: 32, Loss: 0.4645\n",
            "Val AP: 0.9688, Val AUC: 0.9645\n",
            "Test AP: 0.9632, Test AUC: 0.9591\n",
            "Epoch: 33, Loss: 0.4496\n",
            "Val AP: 0.9710, Val AUC: 0.9670\n",
            "Test AP: 0.9652, Test AUC: 0.9611\n",
            "Epoch: 34, Loss: 0.4450\n",
            "Val AP: 0.9691, Val AUC: 0.9653\n",
            "Test AP: 0.9635, Test AUC: 0.9601\n",
            "Epoch: 35, Loss: 0.4512\n",
            "Val AP: 0.9691, Val AUC: 0.9650\n",
            "Test AP: 0.9640, Test AUC: 0.9592\n",
            "Epoch: 36, Loss: 0.4397\n",
            "Val AP: 0.9708, Val AUC: 0.9671\n",
            "Test AP: 0.9657, Test AUC: 0.9622\n",
            "Epoch: 37, Loss: 0.4333\n",
            "Val AP: 0.9699, Val AUC: 0.9660\n",
            "Test AP: 0.9654, Test AUC: 0.9614\n",
            "Epoch: 38, Loss: 0.4256\n",
            "Val AP: 0.9705, Val AUC: 0.9667\n",
            "Test AP: 0.9649, Test AUC: 0.9612\n",
            "Epoch: 39, Loss: 0.4262\n",
            "Val AP: 0.9705, Val AUC: 0.9663\n",
            "Test AP: 0.9650, Test AUC: 0.9607\n",
            "Epoch: 40, Loss: 0.4332\n",
            "Val AP: 0.9709, Val AUC: 0.9670\n",
            "Test AP: 0.9648, Test AUC: 0.9615\n",
            "Epoch: 41, Loss: 0.4274\n",
            "Val AP: 0.9705, Val AUC: 0.9670\n",
            "Test AP: 0.9646, Test AUC: 0.9607\n",
            "Epoch: 42, Loss: 0.4230\n",
            "Val AP: 0.9703, Val AUC: 0.9668\n",
            "Test AP: 0.9654, Test AUC: 0.9615\n",
            "Epoch: 43, Loss: 0.4273\n",
            "Val AP: 0.9686, Val AUC: 0.9655\n",
            "Test AP: 0.9634, Test AUC: 0.9593\n",
            "Epoch: 44, Loss: 0.4251\n",
            "Val AP: 0.9684, Val AUC: 0.9663\n",
            "Test AP: 0.9631, Test AUC: 0.9599\n",
            "Epoch: 45, Loss: 0.4237\n",
            "Val AP: 0.9690, Val AUC: 0.9666\n",
            "Test AP: 0.9636, Test AUC: 0.9604\n",
            "Epoch: 46, Loss: 0.4213\n",
            "Val AP: 0.9689, Val AUC: 0.9665\n",
            "Test AP: 0.9629, Test AUC: 0.9592\n",
            "Epoch: 47, Loss: 0.4183\n",
            "Val AP: 0.9704, Val AUC: 0.9679\n",
            "Test AP: 0.9607, Test AUC: 0.9581\n",
            "Epoch: 48, Loss: 0.4192\n",
            "Val AP: 0.9704, Val AUC: 0.9673\n",
            "Test AP: 0.9638, Test AUC: 0.9597\n",
            "Epoch: 49, Loss: 0.4131\n",
            "Val AP: 0.9701, Val AUC: 0.9668\n",
            "Test AP: 0.9637, Test AUC: 0.9590\n",
            "Epoch: 50, Loss: 0.4056\n",
            "Val AP: 0.9694, Val AUC: 0.9669\n",
            "Test AP: 0.9629, Test AUC: 0.9589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iJl066pJU7cY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above operation is summarized as follows:\n",
        "\n",
        "1. Neighbourhood extraction\n",
        "\n",
        "Let $(\\mathbf{n}, E, \\mathbf{e})$ be the neighbourhood loader. It sampes the 10 most-recent edges per node. For each $u \\rightarrow v$ and the id event $e$ we have the timestamp $t_e$ and the message $x_e$.\n",
        "\n",
        "2. Memory read and temporal attention\n",
        "\n",
        "Lets read the memories as $S = \\{ s_{i} (t) \\}_{i \\in \\mathbf{n}}$ and last updates $\\tilde{t}_i$.The edge features are built as\n",
        "\n",
        "\\begin{equation}\n",
        "a_{uv} = [ \\phi(\\tilde{t}_u - t_e) || x_e]\n",
        "\\end{equation}\n",
        "\n",
        "The one-layer transformer style attention to this subgraph is computed as,\n",
        "\n",
        "\\begin{equation}\n",
        "z_{i} (t) = \\text{TransformerConv} (s_{i} (t), (u \\rightarrow v), a_{uv})\n",
        "\\end{equation}\n",
        "This is an instance of TGN’s temporal attention with time encodings and edge features in the keys/values.\n",
        "\n",
        "3. Decoding and Loss\n",
        "\n",
        "For each positive $(i,j)$ and a sampled negative $(i, \\tilde{j})$\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ij} = \\sigma (w^T \\sigma (W_s z_i + W_d z_j)), \\hat{y}_{i\\tilde{j}} = \\sigma (w^T \\sigma (W_s z_i + W_d z_j))\n",
        "\\end{equation}\n",
        "\n",
        "and $\\mathcal{L} = \\text{BCE}(\\hat{y}_{ij}, 1)+ \\text{BCE}(\\hat{y}_{i\\tilde{j}}, 0)$\n",
        "\n",
        "4. Memory update\n",
        "\n",
        "Store the raw messages for the batch interactions\n",
        "\n",
        "$m^{\\text{raw}}_i = (s_i (t), s_j (t), t, x_{ij}(t))$\n",
        "\n",
        "Design Choices\n",
        "\n",
        "1. One attention layer + memory both accurate and fast.\n",
        "2. Last message aggregation is efficient and competitive; mean aggregation can be slightly better but is much slower.\n",
        "3. Most-recent neighbor sampling outperforms uniform sampling on dynamic graphs.\n"
      ],
      "metadata": {
        "id": "YP1ckzg4a1Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aSwh-nkA3YkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}