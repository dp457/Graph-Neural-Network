{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFY/xRNGs7f4PrOnybTHL9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dp457/Graph-Neural-Network/blob/main/Creating_Graph_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although PyG already contains a lot of useful datasets, we may wish to create your own dataset with self-recorded or non-publicly available data.\n",
        "\n",
        "Implementing datasets by yourself is straightforward and you may want to take a look at the source code to find out how the various datasets are implemented. However, we give a brief introduction on what is needed to setup your own dataset."
      ],
      "metadata": {
        "id": "qUAJZrOnKO7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbM36k3MMxLB",
        "outputId": "bd0e5b91-359c-4e09-8010-33d29b133aaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# In-Memory Datasets"
      ],
      "metadata": {
        "id": "WC-XwVHYKVOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch_geometric.data import InMemoryDataset, Data, download_url # aim is to fit it entirely in the meory\n",
        "# Data - fundamental container for the single graph\n",
        "# download_url - help fetch files from internet\n",
        "\n",
        "class MyOwnDataset(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "        # root - where dataset is stored\n",
        "        # trasform - applied on the fly when we access the graph\n",
        "        # prefilter - filter out certain graphs\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.load(self.processed_paths[0])   # For PyG>=2.4\n",
        "        # For PyG<2.4, use:\n",
        "        # self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        # List of files expected in `raw_dir`\n",
        "        return ['some_file_1.txt', 'some_file_2.txt']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        # List of files written to `processed_dir`\n",
        "        return ['data.pt']\n",
        "\n",
        "    def download(self):\n",
        "        # Example: download from URLs\n",
        "        # url = \"https://example.com/data.txt\"\n",
        "        # download_url(url, self.raw_dir)\n",
        "        pass   # If you already have raw files, leave this empty\n",
        "\n",
        "    def process(self):\n",
        "        data_list = []\n",
        "\n",
        "        # Example 1: first graph with 3 nodes and 2 edges\n",
        "        x = torch.tensor([[1], [2], [3]], dtype=torch.float)         # 3 nodes each with 1 feature\n",
        "        edge_index = torch.tensor([[0, 1], [1, 2]], dtype=torch.long).t().contiguous() # edge list with shape [2, num_edges]\n",
        "        y = torch.tensor([0])   # graph label\n",
        "        data = Data(x=x, edge_index=edge_index, y=y) # wrap it into data and to dataset\n",
        "        data_list.append(data)\n",
        "\n",
        "        # Example 2: second graph with 4 nodes\n",
        "        x = torch.tensor([[1], [0], [1], [0]], dtype=torch.float) # graph with 4 nodes\n",
        "        edge_index = torch.tensor([[0, 1, 2, 3], [1, 0, 3, 2]], dtype=torch.long)\n",
        "        y = torch.tensor([1])\n",
        "        data = Data(x=x, edge_index=edge_index, y=y)\n",
        "        data_list.append(data)\n",
        "\n",
        "        # Apply optional pre_filter\n",
        "        if self.pre_filter is not None:\n",
        "            data_list = [d for d in data_list if self.pre_filter(d)]\n",
        "\n",
        "        # Apply optional pre_transform\n",
        "        if self.pre_transform is not None:\n",
        "            data_list = [self.pre_transform(d) for d in data_list]\n",
        "\n",
        "        # Save processed dataset\n",
        "        self.save(data_list, self.processed_paths[0])\n",
        "        # For PyG<2.4:\n",
        "        # torch.save(self.collate(data_list), self.processed_paths[0])\n"
      ],
      "metadata": {
        "id": "tyiK-u--KkT6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "__b5d4v6Mv-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Larger Dataset online"
      ],
      "metadata": {
        "id": "qrLogDVZOFs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Dataset, download_url, Data\n",
        "\n",
        "\n",
        "class MyOwnDataset(Dataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        # After download, PyG will check if this file exists in raw_dir\n",
        "        return ['karate.gml']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        # Processed dataset files to save\n",
        "        return ['data_0.pt']\n",
        "\n",
        "    def download(self):\n",
        "        # Example: download Zachary's Karate Club graph in GML format\n",
        "        url = 'https://raw.githubusercontent.com/networkx/networkx/main/networkx/readwrite/gml/tests/fixtures/karate.gml'\n",
        "        download_url(url, self.raw_dir)\n",
        "\n",
        "    def process(self):\n",
        "        import networkx as nx\n",
        "        from torch_geometric.utils import from_networkx\n",
        "\n",
        "        raw_path = osp.join(self.raw_dir, 'karate.gml')\n",
        "        G = nx.read_gml(raw_path, label='id')  # read GML graph\n",
        "        data = from_networkx(G)  # convert to PyG Data object\n",
        "\n",
        "        # Example: assign random features\n",
        "        data.x = torch.eye(data.num_nodes)  # identity as features\n",
        "        data.y = torch.zeros(data.num_nodes, dtype=torch.long)  # dummy labels\n",
        "\n",
        "        if self.pre_filter is not None and not self.pre_filter(data):\n",
        "            return\n",
        "\n",
        "        if self.pre_transform is not None:\n",
        "            data = self.pre_transform(data)\n",
        "\n",
        "        torch.save(data, osp.join(self.processed_dir, 'data_0.pt'))\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "        return data\n"
      ],
      "metadata": {
        "id": "SuBLo4WuOKBk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ic4vV5kLKR6X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}